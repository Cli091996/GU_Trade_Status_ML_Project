{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae8e9657",
   "metadata": {},
   "source": [
    "### Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d98cbd8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T00:56:57.388360Z",
     "start_time": "2024-04-09T00:56:55.372498Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier,RandomForestClassifier,BaggingClassifier,AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import Pipeline \n",
    "import xgboost as xgb\n",
    "\n",
    "#Need to clean further \n",
    "from Standardization import metric_normalizer\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer, MinMaxScaler,OneHotEncoder, OrdinalEncoder\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, classification_report  # Import accuracy_score\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder,StandardScaler, Normalizer, MinMaxScaler\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.feature_selection import SelectPercentile, mutual_info_classif\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, cross_val_predict\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report,ConfusionMatrixDisplay, f1_score, precision_score, recall_score\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "\n",
    "# Filter out UndefinedMetricWarning\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c529ee",
   "metadata": {},
   "source": [
    "### Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9702d08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T00:56:57.432868Z",
     "start_time": "2024-04-09T00:56:57.392464Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/clivence/base_jupyter/Datadump/Model_Data/GU_Model_Data_V1_16k')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8f7a4c",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cab67ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T00:56:57.748834Z",
     "start_time": "2024-04-09T00:56:57.437636Z"
    }
   },
   "outputs": [],
   "source": [
    "#Filter out negative values - evetually need to research why this is happening \n",
    "df  = df[(df['2D Low in Pips'] > 0) | (df['2D Low in Pips'] > 0)] \n",
    "\n",
    "df = df[df['Action'] == 'Ultimate Action']\n",
    "df = df[df['Ticker'] == 'GBP/USD']\n",
    "\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "#Standardize the dataset\n",
    "df =  metric_normalizer(df)\n",
    "\n",
    "#Set date to datetime \n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "#Create Date Derived Features \n",
    "df['Trade_Week_Year'] = df['Date'].dt.isocalendar().week\n",
    "df['Trade_Week_Month'] = (df['Date'].dt.day -1)//7+1\n",
    "df['Trade_Day_Week'] = df['Date'].dt.weekday + 1\n",
    "\n",
    "#Create a new feature to identify the status of the previous trade \n",
    "df['Previous_Trade_Status'] = df['2D Trade Status'].shift(fill_value=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02cf35d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-20T20:41:50.452097Z",
     "start_time": "2024-01-20T20:41:50.416223Z"
    }
   },
   "source": [
    "### Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e98da383",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T00:56:57.793872Z",
     "start_time": "2024-04-09T00:56:57.765611Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Subset Selection\n",
    "df = df[['open', 'high', 'low', 'close', 'volume','Trade_Week_Year','Trade_Week_Month','Trade_Day_Week',\n",
    "       'Day','Month','25EMA', '50EMA', '75EMA','100EMA', '125EMA',\n",
    "        'Trend Status', 'Spread','5075 Trend Status', '75100 Trend Status',\n",
    "       '100125 Trend Status', 'Order Type', \n",
    "        '%K', '%D', 'k_group', 'ADX', 'ADXR', 'slowk','slowd','CDL2CROWS', 'CDL3BLACKCROWS',\n",
    "        'CDL3INSIDE', 'CDL3LINESTRIKE', 'CDL3OUTSIDE',\n",
    "        'CDL3STARSINSOUTH', 'CDL3WHITESOLDIERS', 'CDLABANDONEDBABY', 'CDLADVANCEBLOCK',\n",
    "        'CDLBELTHOLD', 'CDLBREAKAWAY', 'CDLCLOSINGMARUBOZU', 'CDLCONCEALBABYSWALL',\n",
    "        'CDLCOUNTERATTACK', 'CDLDARKCLOUDCOVER', 'CDLDOJI', 'CDLDOJISTAR', 'CDLDRAGONFLYDOJI',\n",
    "        'CDLENGULFING', 'CDLEVENINGDOJISTAR', 'CDLEVENINGSTAR', 'CDLGAPSIDESIDEWHITE',\n",
    "        'CDLGRAVESTONEDOJI', 'CDLHAMMER', 'CDLHANGINGMAN', 'CDLHARAMI', 'CDLHARAMICROSS',\n",
    "        'CDLHIGHWAVE', 'CDLHIKKAKE', 'CDLHIKKAKEMOD', 'CDLHOMINGPIGEON', 'CDLIDENTICAL3CROWS',\n",
    "        'CDLINNECK', 'CDLINVERTEDHAMMER', 'CDLKICKING', 'CDLKICKINGBYLENGTH', 'CDLLADDERBOTTOM',\n",
    "        'CDLLONGLEGGEDDOJI', 'CDLLONGLINE', 'CDLMARUBOZU', 'CDLMATCHINGLOW', 'CDLMATHOLD',\n",
    "        'CDLMORNINGDOJISTAR', 'CDLMORNINGSTAR', 'CDLONNECK', 'CDLPIERCING', 'CDLRICKSHAWMAN',\n",
    "        'CDLRISEFALL3METHODS', 'CDLSEPARATINGLINES', 'CDLSHOOTINGSTAR', 'CDLSHORTLINE',\n",
    "        'CDLSPINNINGTOP', 'CDLSTALLEDPATTERN', 'CDLSTICKSANDWICH', 'CDLTAKURI', 'CDLTASUKIGAP',\n",
    "        'CDLTHRUSTING', 'CDLTRISTAR', 'CDLUNIQUE3RIVER', 'CDLUPSIDEGAP2CROWS', 'CDLXSIDEGAP3METHODS',\n",
    "        'candle_bullish_score','candle_bearish_score','Previous_Trade_Status','2D Trade Status']]\n",
    "\n",
    "#Set a random state \n",
    "state =42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31cfbd0f-5c09-49b4-8fad-f6d882992794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 386\n",
      "Test: 48\n",
      "Validation: 49\n"
     ]
    }
   ],
   "source": [
    "# set training, test, and validation set size \n",
    "total_len = len(df)\n",
    "training_size = int(total_len * .8)\n",
    "test_size = int(total_len * .1)\n",
    "validation_size = total_len - training_size - test_size\n",
    "\n",
    "# Split indices\n",
    "training_idx = df.index[:training_size]\n",
    "test_idx = df.index[training_size:training_size + test_size]\n",
    "validation_idx = df.index[-validation_size:]\n",
    "\n",
    "# Verify lengths\n",
    "assert len(training_idx) == training_size\n",
    "assert len(test_idx) == test_size\n",
    "assert len(validation_idx) == validation_size\n",
    "\n",
    "# Create training, test, and validation df \n",
    "training_df = df.loc[training_idx]\n",
    "test_df = df.loc[test_idx]\n",
    "validation_df = df.loc[validation_idx]\n",
    "\n",
    "# Print lengths of the three DataFrames\n",
    "print(f\"Training: {len(training_df)}\")\n",
    "print(f\"Test: {len(test_df)}\")\n",
    "print(f\"Validation: {len(validation_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba7e9593-a73f-45dd-8761-b779c0a4d12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = training_df.drop(columns=['2D Trade Status'])\n",
    "y_train = training_df['2D Trade Status']\n",
    "X_test = test_df.drop(columns=['2D Trade Status'])\n",
    "y_test = test_df['2D Trade Status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93418d9f-c87f-4663-8f79-9a9932b166f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list of columns to encode \n",
    "cat_cols_to_encode = ['Order Type']\n",
    "#Create a list of cols for ordinal encoding \n",
    "cat_cols_for_ordinal_encoding = ['Trend Status','5075 Trend Status', '75100 Trend Status',\n",
    "                    '100125 Trend Status','k_group']\n",
    "\n",
    "#Create a list of cols to scale \n",
    "num_cols_to_scale = ['volume']\n",
    "\n",
    "# Create Column Transformer with appropriate preprocessing for numerical and categorical data\n",
    "Preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='median')),  # Handle missing values\n",
    "            ('scaler', MinMaxScaler())]), num_cols_to_scale),\n",
    "        ('cat_onehot', OneHotEncoder(drop='first', sparse_output=False), cat_cols_to_encode),\n",
    "        ('cat_ordinal', OrdinalEncoder(), cat_cols_for_ordinal_encoding)\n",
    "    ],\n",
    "    remainder='passthrough')\n",
    "\n",
    "# Preprocessor.set_output(transform='pandas')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d686faf5",
   "metadata": {},
   "source": [
    "## Base Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d80b70e-d52d-4ff1-945b-5018080dc5f4",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d28d085f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T00:56:57.908090Z",
     "start_time": "2024-04-09T00:56:57.878046Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 0.6458333333333334\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Loss Trades       0.00      0.00      0.00        13\n",
      "  Win Trades       0.70      0.89      0.78        35\n",
      "\n",
      "    accuracy                           0.65        48\n",
      "   macro avg       0.35      0.44      0.39        48\n",
      "weighted avg       0.51      0.65      0.57        48\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/clivence/base_jupyter/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#Create PiPeline to be used in Model\n",
    "Base_LR_Model_Pipeline = Pipeline(steps=[\n",
    "    ('Preprocessor', Preprocessor),\n",
    "    ('RF_Model',LogisticRegression())])\n",
    "\n",
    "# Perform cross-validation\n",
    "Base_LR_Model_Pipeline.fit(X_train, y_train)\n",
    "Base_LR_Model_Predictions = Base_LR_Model_Pipeline.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, Base_LR_Model_Predictions)\n",
    "print(f\"\\nTest Accuracy: {accuracy}\\n\")\n",
    "\n",
    "# Generate and Print  classification report\n",
    "report = classification_report(y_test, Base_LR_Model_Predictions, target_names=[\"Loss Trades\", \"Win Trades\"]) \n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65404f40-394e-4b5d-a038-d6d31cb8d843",
   "metadata": {},
   "source": [
    "## Logistic Regression Summary and Key Takeaways\n",
    "\n",
    "### Performance Overview\n",
    "- **Test Accuracy**: Approximately 64.6%.\n",
    "\n",
    "### Insights from Classification Report\n",
    "- **'Win Trades' (Positive Class)**:\n",
    "  - Precision: ~70%\n",
    "  - Recall: ~89%\n",
    "  - F1-score: ~0.78\n",
    "- **'Loss Trades' (Negative Class)**:\n",
    "  - Precision: 0% (no correct predictions for this class)\n",
    "  - Recall: 0%\n",
    "  - F1-score: 0.00\n",
    "\n",
    "### Key Takeaways\n",
    "1. **Limited Performance on Minority Class**:\n",
    "   - The model performs reasonably well in predicting 'Win Trades' but fails to correctly identify 'Loss Trades', leading to significant class imbalance issues.\n",
    "2. **Imbalance Remediation Needed**:\n",
    "   - Addressing the class imbalance through techniques like adjusting class weights, resampling, or using different algorithms is critical to improving overall model performance and fairness.\n",
    "3. **Evaluation Beyond Accuracy**:\n",
    "   - While accuracy is an essential metric, it fails to capture the model's performance accurately in the presence of class imbalance. Metrics like precision, recall, and the F1-score provide a more comprehensive understanding of the model's capabilities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e887c858-9cf6-4545-99b8-2fb7ef2376bf",
   "metadata": {},
   "source": [
    "### Support Vector Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "baba87c1-2a2e-42f8-bb74-e5ee33c296aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 0.7291666666666666\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Loss Trades       0.00      0.00      0.00        13\n",
      "  Win Trades       0.73      1.00      0.84        35\n",
      "\n",
      "    accuracy                           0.73        48\n",
      "   macro avg       0.36      0.50      0.42        48\n",
      "weighted avg       0.53      0.73      0.61        48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create Pipeline to be used in SVC Model\n",
    "Base_SVC_Model_Pipeline = Pipeline(steps=[\n",
    "    ('Preprocessor', Preprocessor),\n",
    "    ('SVC_Model',SVC(random_state=state))])\n",
    "\n",
    "#Fit the training data \n",
    "Base_SVC_Model_Pipeline.fit(X_train, y_train)\n",
    "\n",
    "#Make Predictions on the test set \n",
    "Base_SVC_Model_Predictions = Base_SVC_Model_Pipeline.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, Base_SVC_Model_Predictions)\n",
    "print(f\"\\nTest Accuracy: {accuracy}\\n\")\n",
    "\n",
    "# Generate  and Print a classification report\n",
    "report = classification_report(y_test, Base_SVC_Model_Predictions, target_names=[\"Loss Trades\", \"Win Trades\"]) \n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13edce20-a233-4a6e-ba2d-845bec6c8ca3",
   "metadata": {},
   "source": [
    "## Support Vector Machine Summary and Key Takeaways\n",
    "\n",
    "### Performance Overview\n",
    "- **Test Accuracy**: Approximately 71-73%.\n",
    "\n",
    "### Insights from Classification Report\n",
    "- **'Win Trades' (Positive Class)**:\n",
    "  - Precision: ~73%\n",
    "  - Recall: ~94%\n",
    "  - F1-score: ~0.82\n",
    "- **'Loss Trades' (Negative Class)**:\n",
    "  - Precision: Varies, often low (0-33%)\n",
    "  - Recall: Often low (0-8%)\n",
    "  - F1-score: Varies, often low (0-0.12)\n",
    "\n",
    "### Key Takeaways\n",
    "1. **Imbalance in Class Performance**:\n",
    "   - Model excels in predicting 'Win Trades' but struggles with 'Loss Trades', particularly in recall.\n",
    "2. **Model Optimization for Minority Class**:\n",
    "   - Further optimization needed to improve prediction of 'Loss Trades'. Consider techniques like adjusting class weights or oversampling.\n",
    "3. **Consider Data Quality and Representation**:\n",
    "   - Ensure test set is representative. Investigate reasons for low performance in predicting 'Loss Trades'.\n",
    "4. **Iterative Model Refinement**:\n",
    "   - Experiment with different algorithms, feature engineering, and hyperparameter tuning to achieve better balance between precision and recall for both classes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86cc108-945e-41fc-acf9-2f575a5befb7",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "21c2371e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T00:56:57.953249Z",
     "start_time": "2024-04-09T00:56:57.943959Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 0.6041666666666666\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Loss Trades       0.25      0.23      0.24        13\n",
      "  Win Trades       0.72      0.74      0.73        35\n",
      "\n",
      "    accuracy                           0.60        48\n",
      "   macro avg       0.49      0.49      0.49        48\n",
      "weighted avg       0.59      0.60      0.60        48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create Pipeline to be used in Descision Tree Model\n",
    "Base_DT_Model_Pipeline = Pipeline(steps=[\n",
    "    ('Preprocessor', Preprocessor),\n",
    "    ('DT_Model',DecisionTreeClassifier(random_state=state))])\n",
    "\n",
    "#Fit the training data \n",
    "Base_DT_Model_Pipeline.fit(X_train, y_train)\n",
    "\n",
    "#Make Predictions on the test set \n",
    "Base_DT_Model_Predictions = Base_DT_Model_Pipeline.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, Base_DT_Model_Predictions)\n",
    "print(f\"\\nTest Accuracy: {accuracy}\\n\")\n",
    "\n",
    "# Generate  and Print a classification report\n",
    "report = classification_report(y_test, Base_DT_Model_Predictions, target_names=[\"Loss Trades\", \"Win Trades\"]) \n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503d12cb-69a9-45fc-8f4a-7e410431b15e",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier Summary and Key Takeaways\n",
    "\n",
    "### Performance Overview\n",
    "- **Test Accuracy**: Approximately 60.4%.\n",
    "\n",
    "### Insights from Classification Report\n",
    "- **'Win Trades' (Positive Class)**:\n",
    "  - Precision: ~72%\n",
    "  - Recall: ~74%\n",
    "  - F1-score: ~0.73\n",
    "- **'Loss Trades' (Negative Class)**:\n",
    "  - Precision: ~25%\n",
    "  - Recall: ~23%\n",
    "  - F1-score: ~0.24\n",
    "\n",
    "### Key Takeaways\n",
    "1. **Imbalance in Class Performance**:\n",
    "   - Model performs better in predicting 'Win Trades' compared to 'Loss Trades'.\n",
    "2. **Model Optimization**:\n",
    "   - Consider model parameter tuning or alternative algorithms to improve overall performance.\n",
    "3. **Interpretability**:\n",
    "   - Decision trees provide interpretable models, but their performance may vary based on the dataset and its characteristics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fa387f-ff3d-45e1-a995-edc94f7e0ee7",
   "metadata": {},
   "source": [
    "### ADA Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "843a00f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T07:23:59.563409Z",
     "start_time": "2024-04-09T07:23:59.042675Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/clivence/base_jupyter/venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 0.6875\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Loss Trades       0.25      0.08      0.12        13\n",
      "  Win Trades       0.73      0.91      0.81        35\n",
      "\n",
      "    accuracy                           0.69        48\n",
      "   macro avg       0.49      0.50      0.46        48\n",
      "weighted avg       0.60      0.69      0.62        48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create PiPeline to be used in Model\n",
    "Base_ADAC_Model_Pipeline = Pipeline(steps=[\n",
    "    ('Preprocessor', Preprocessor),\n",
    "    ('RF_Model',AdaBoostClassifier(random_state=state))])\n",
    "\n",
    "#Fit the training data \n",
    "Base_ADAC_Model_Pipeline.fit(X_train, y_train)\n",
    "\n",
    "#Make Predictions on the test set \n",
    "Base_ADAC_Model_Predictions = Base_ADAC_Model_Pipeline.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, Base_ADAC_Model_Predictions)\n",
    "print(f\"\\nTest Accuracy: {accuracy}\\n\")\n",
    "\n",
    "# Generate  and Print a classification report\n",
    "report = classification_report(y_test, Base_ADAC_Model_Predictions, target_names=[\"Loss Trades\", \"Win Trades\"]) \n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db264755-4ab4-46af-aa49-0502fbf8ac19",
   "metadata": {},
   "source": [
    "## ADA Boost Classifier Summary and Key Takeaways\n",
    "\n",
    "### Performance Overview\n",
    "- **Test Accuracy**: Approximately 68.8%.\n",
    "\n",
    "### Insights from Classification Report\n",
    "- **'Win Trades' (Positive Class)**:\n",
    "  - Precision: ~73%\n",
    "  - Recall: ~91%\n",
    "  - F1-score: ~0.81\n",
    "- **'Loss Trades' (Negative Class)**:\n",
    "  - Precision: ~25%\n",
    "  - Recall: ~8%\n",
    "  - F1-score: ~0.12\n",
    "\n",
    "### Key Takeaways\n",
    "1. **Imbalance in Class Performance**:\n",
    "   - Model performs significantly better in predicting 'Win Trades' compared to 'Loss Trades'.\n",
    "2. **Model Optimization**:\n",
    "   - Consider adjusting model parameters or exploring different algorithms to improve performance, particularly for the minority class.\n",
    "3. **Data Imbalance Consideration**:\n",
    "   - Addressing class imbalance may help improve the overall performance and reliability of the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b9acc4-9968-4ed9-b98a-a43a0aa7b635",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d5424f55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T00:57:11.309858Z",
     "start_time": "2024-04-09T00:56:57.958725Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 0.7291666666666666\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Loss Trades       0.00      0.00      0.00        13\n",
      "  Win Trades       0.73      1.00      0.84        35\n",
      "\n",
      "    accuracy                           0.73        48\n",
      "   macro avg       0.36      0.50      0.42        48\n",
      "weighted avg       0.53      0.73      0.61        48\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/clivence/base_jupyter/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/clivence/base_jupyter/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/clivence/base_jupyter/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Create Model Pipeline\n",
    "Base_RF_Model_Pipeline = Pipeline(steps=[\n",
    "    ('Preprocessor', Preprocessor),\n",
    "    ('RF_Model', RandomForestClassifier(random_state=state))  \n",
    "])\n",
    "\n",
    "#Fit the training data \n",
    "Base_RF_Model_Pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make Predictions\n",
    "RF_CV_predictions = Base_RF_Model_Pipeline.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, RF_CV_predictions)\n",
    "print(f\"\\nTest Accuracy: {accuracy}\\n\")\n",
    "\n",
    "# Generate  and Print a classification report\n",
    "report = classification_report(y_test, RF_CV_predictions, target_names=[\"Loss Trades\", \"Win Trades\"]) \n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6c67c9-a1c3-4d65-8515-4a059ff72af3",
   "metadata": {},
   "source": [
    "## Random Forest Classifier Summary and Key Takeaways\n",
    "\n",
    "### Performance Overview\n",
    "- **Test Accuracy**: Approximately 72.9%.\n",
    "\n",
    "### Insights from Classification Report\n",
    "- **'Win Trades' (Positive Class)**:\n",
    "  - Precision: ~73%\n",
    "  - Recall: 100%\n",
    "  - F1-score: ~0.84\n",
    "- **'Loss Trades' (Negative Class)**:\n",
    "  - Precision: 0% (no correct predictions for this class)\n",
    "  - Recall: 0%\n",
    "  - F1-score: 0.00\n",
    "\n",
    "### Key Takeaways\n",
    "1. **Severe Class Imbalance Impact**:\n",
    "   - The model predicts 'Win Trades' with high recall but completely fails to identify 'Loss Trades', indicating a possible overfitting to the majority class.\n",
    "2. **Urgent Need for Model Calibration**:\n",
    "   - It is crucial to address the overfitting and improve the sensitivity towards the 'Loss Trades' by adjusting class weights, trying different algorithms, or employing techniques like resampling to balance the classes.\n",
    "3. **Model Evaluation**:\n",
    "   - This scenario underscores the importance of using metrics beyond accuracy, such as precision, recall, and the F1-score, to truly understand model performance, particularly in the presence of class imbalance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e24abfd-d659-4281-b0ca-25f66b392f16",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3c5ee128-1072-410c-93aa-c849be9bdae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 0.7291666666666666\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Loss Trades       0.50      0.08      0.13        13\n",
      "  Win Trades       0.74      0.97      0.84        35\n",
      "\n",
      "    accuracy                           0.73        48\n",
      "   macro avg       0.62      0.52      0.49        48\n",
      "weighted avg       0.67      0.73      0.65        48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create Pipeline to be used in Gradient Boosting Classfier Model\n",
    "Base_GBC_Model_Pipeline = Pipeline(steps=[\n",
    "    ('Preprocessor', Preprocessor),\n",
    "    ('GBC_Model',GradientBoostingClassifier(random_state=state))])\n",
    "\n",
    "#Fit the training data \n",
    "Base_GBC_Model_Pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Perform cross-validation\n",
    "GBC_predictions = Base_GBC_Model_Pipeline.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, GBC_predictions)\n",
    "print(f\"\\nTest Accuracy: {accuracy}\\n\")\n",
    "\n",
    "# Generate  and Print a classification report\n",
    "report = classification_report(y_test, GBC_predictions, target_names=[\"Loss Trades\", \"Win Trades\"]) \n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6af6981-1470-455b-b5b4-8b500c604519",
   "metadata": {},
   "source": [
    "## Gradient Boosting Classifier Summary and Key Takeaways\n",
    "\n",
    "### Performance Overview\n",
    "- **Test Accuracy**: Approximately 72.9%.\n",
    "\n",
    "### Insights from Classification Report\n",
    "- **'Win Trades' (Positive Class)**:\n",
    "  - Precision: ~74%\n",
    "  - Recall: ~97%\n",
    "  - F1-score: ~0.84\n",
    "- **'Loss Trades' (Negative Class)**:\n",
    "  - Precision: ~50%\n",
    "  - Recall: ~8%\n",
    "  - F1-score: ~0.13\n",
    "\n",
    "### Key Takeaways\n",
    "1. **Class Imbalance Impact**:\n",
    "   - Model shows good performance in predicting 'Win Trades' but struggles with 'Loss Trades', as reflected in low recall for the negative class.\n",
    "2. **Need for Class Balance**:\n",
    "   - Address class imbalance to improve the model's ability to predict 'Loss Trades' accurately.\n",
    "3. **Model Fine-Tuning**:\n",
    "   - Explore parameter tuning or different algorithms to enhance overall model performance, particularly for minority classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "012c577b-9f7c-4697-b939-c3e5d5c80b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 0.6875\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Loss Trades       0.25      0.08      0.12        13\n",
      "  Win Trades       0.73      0.91      0.81        35\n",
      "\n",
      "    accuracy                           0.69        48\n",
      "   macro avg       0.49      0.50      0.46        48\n",
      "weighted avg       0.60      0.69      0.62        48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create Pipeline to be used in Gradient Boosting Classfier Model\n",
    "Base_XGB_Model_Pipeline = Pipeline(steps=[\n",
    "    ('Preprocessor', Preprocessor),\n",
    "    ('XGB_Model',xgb.XGBClassifier(random_state=state))])\n",
    "\n",
    "#Fit the training data \n",
    "Base_XGB_Model_Pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Perform cross-validation\n",
    "XGB_predictions = Base_XGB_Model_Pipeline.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, XGB_predictions)\n",
    "print(f\"\\nTest Accuracy: {accuracy}\\n\")\n",
    "\n",
    "# Generate  and Print a classification report\n",
    "report = classification_report(y_test, XGB_predictions, target_names=[\"Loss Trades\", \"Win Trades\"]) \n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c931de3f-b72d-430f-b9c4-afd300711c09",
   "metadata": {},
   "source": [
    "## XGBoost Classifier Summary and Key Takeaways\n",
    "\n",
    "### Performance Overview\n",
    "- **Test Accuracy**: Approximately 68.75%.\n",
    "\n",
    "### Insights from Classification Report\n",
    "- **'Win Trades' (Positive Class)**:\n",
    "  - Precision: ~73%\n",
    "  - Recall: ~91%\n",
    "  - F1-score: ~0.81\n",
    "- **'Loss Trades' (Negative Class)**:\n",
    "  - Precision: ~25%\n",
    "  - Recall: ~8%\n",
    "  - F1-score: ~0.12\n",
    "\n",
    "### Key Takeaways\n",
    "1. **Limited Ability in Predicting 'Loss Trades'**:\n",
    "   - The model is able to predict 'Win Trades' fairly effectively, but shows very limited ability to correctly identify 'Loss Trades'.\n",
    "2. **Improvement Needed in Negative Class Recognition**:\n",
    "   - Significant improvements are needed in recognizing the negative class to reduce the model's bias towards 'Win Trades'.\n",
    "3. **Potential Strategies for Enhancement**:\n",
    "   - Consider revising the model parameters, using different feature selection techniques, or applying balanced class weighting strategies to better address class imbalance and improve overall model fairness.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26965693-3e48-4e74-8a6f-cf806bf95605",
   "metadata": {},
   "source": [
    "## Cross Validate Top Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "69a1fbc1-8d38-4df7-9c6e-fb08644119a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.67948718 0.68831169 0.68831169 0.67532468 0.67532468]\n",
      "Mean CV accuracy: 0.6813519813519813\n",
      "\n",
      "Test Accuracy: 0.7291666666666666\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Loss Trades       0.00      0.00      0.00        13\n",
      "  Win Trades       0.73      1.00      0.84        35\n",
      "\n",
      "    accuracy                           0.73        48\n",
      "   macro avg       0.36      0.50      0.42        48\n",
      "weighted avg       0.53      0.73      0.61        48\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/clivence/base_jupyter/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/clivence/base_jupyter/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/clivence/base_jupyter/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Create Model Pipeline \n",
    "Base_SVC_Model_Pipeline = Pipeline(steps=[\n",
    "    ('Preprocessor', Preprocessor), \n",
    "    ('SVC_Model', SVC())\n",
    "])\n",
    "\n",
    "# Fit the model using cross-validation\n",
    "cv_scores = cross_val_score(Base_SVC_Model_Pipeline, X_train, y_train, cv=5) \n",
    "\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean CV accuracy:\", cv_scores.mean())\n",
    "\n",
    "# Fit the model on the entire training data\n",
    "Base_SVC_Model_Pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "Base_SVC_Model_Predictions = Base_SVC_Model_Pipeline.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, Base_SVC_Model_Predictions)\n",
    "print(f\"\\nTest Accuracy: {accuracy}\\n\")\n",
    "\n",
    "# Generate a classification report\n",
    "report = classification_report(y_test, Base_SVC_Model_Predictions, target_names=[\"Loss Trades\", \"Win Trades\"]) \n",
    "print(\"Classification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ad82eaad-ff5d-4e5a-a8bb-56a793daab96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.55128205 0.63636364 0.61038961 0.57142857 0.7012987 ]\n",
      "Mean CV accuracy: 0.6141525141525142\n",
      "\n",
      "Test Accuracy: 0.7291666666666666\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Loss Trades       0.50      0.08      0.13        13\n",
      "  Win Trades       0.74      0.97      0.84        35\n",
      "\n",
      "    accuracy                           0.73        48\n",
      "   macro avg       0.62      0.52      0.49        48\n",
      "weighted avg       0.67      0.73      0.65        48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Create Model Pipeline \n",
    "Base_SVC_Model_Pipeline = Pipeline(steps=[\n",
    "    ('Preprocessor', Preprocessor), \n",
    "    ('GBC_Model',GradientBoostingClassifier())\n",
    "])\n",
    "\n",
    "# Fit the model using cross-validation\n",
    "cv_scores = cross_val_score(Base_SVC_Model_Pipeline, X_train, y_train, cv=5) \n",
    "\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean CV accuracy:\", cv_scores.mean())\n",
    "\n",
    "# Fit the model on the entire training data\n",
    "Base_SVC_Model_Pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "Base_SVC_Model_Predictions = Base_SVC_Model_Pipeline.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, Base_SVC_Model_Predictions)\n",
    "print(f\"\\nTest Accuracy: {accuracy}\\n\")\n",
    "\n",
    "# Generate a classification report\n",
    "report = classification_report(y_test, Base_SVC_Model_Predictions, target_names=[\"Loss Trades\", \"Win Trades\"]) \n",
    "print(\"Classification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7d33376e-979a-4295-a5c9-d19b84f3e7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.48717949 0.67532468 0.62337662 0.50649351 0.5974026 ]\n",
      "Mean CV accuracy: 0.577955377955378\n",
      "\n",
      "Test Accuracy: 0.7291666666666666\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Loss Trades       0.00      0.00      0.00        13\n",
      "  Win Trades       0.73      1.00      0.84        35\n",
      "\n",
      "    accuracy                           0.73        48\n",
      "   macro avg       0.36      0.50      0.42        48\n",
      "weighted avg       0.53      0.73      0.61        48\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/clivence/base_jupyter/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/clivence/base_jupyter/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/clivence/base_jupyter/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Create Model Pipeline \n",
    "Base_SVC_Model_Pipeline = Pipeline(steps=[\n",
    "    ('Preprocessor', Preprocessor), \n",
    "    ('RF_Model', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Fit the model using cross-validation\n",
    "cv_scores = cross_val_score(Base_SVC_Model_Pipeline, X_train, y_train, cv=5) \n",
    "\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean CV accuracy:\", cv_scores.mean())\n",
    "\n",
    "# Fit the model on the entire training data\n",
    "Base_SVC_Model_Pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "Base_SVC_Model_Predictions = Base_SVC_Model_Pipeline.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, Base_SVC_Model_Predictions)\n",
    "print(f\"\\nTest Accuracy: {accuracy}\\n\")\n",
    "\n",
    "# Generate a classification report\n",
    "report = classification_report(y_test, Base_SVC_Model_Predictions, target_names=[\"Loss Trades\", \"Win Trades\"]) \n",
    "print(\"Classification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cd9d85a1-3928-4cb5-82de-bb3d6d5b1c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.6025641  0.61038961 0.61038961 0.50649351 0.51948052]\n",
      "Mean CV accuracy: 0.5698634698634699\n",
      "\n",
      "Test Accuracy: 0.6875\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Loss Trades       0.25      0.08      0.12        13\n",
      "  Win Trades       0.73      0.91      0.81        35\n",
      "\n",
      "    accuracy                           0.69        48\n",
      "   macro avg       0.49      0.50      0.46        48\n",
      "weighted avg       0.60      0.69      0.62        48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Create Model Pipeline \n",
    "Base_SVC_Model_Pipeline = Pipeline(steps=[\n",
    "    ('Preprocessor', Preprocessor), \n",
    "    ('XGB_Model',xgb.XGBClassifier())\n",
    "])\n",
    "\n",
    "# Fit the model using cross-validation\n",
    "cv_scores = cross_val_score(Base_SVC_Model_Pipeline, X_train, y_train, cv=5) \n",
    "\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean CV accuracy:\", cv_scores.mean())\n",
    "\n",
    "# Fit the model on the entire training data\n",
    "Base_SVC_Model_Pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "Base_SVC_Model_Predictions = Base_SVC_Model_Pipeline.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, Base_SVC_Model_Predictions)\n",
    "print(f\"\\nTest Accuracy: {accuracy}\\n\")\n",
    "\n",
    "# Generate a classification report\n",
    "report = classification_report(y_test, Base_SVC_Model_Predictions, target_names=[\"Loss Trades\", \"Win Trades\"]) \n",
    "print(\"Classification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea0e4ab-666c-4785-9bed-76bcd16a30df",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae1d3cb-5a0e-4399-888f-52237a5383f9",
   "metadata": {},
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541a4b54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T07:23:54.105403Z",
     "start_time": "2024-04-09T00:57:11.312604Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid to use for the grid search\n",
    "param_grid = {\n",
    "    'RF_Model__n_estimators': [25,50, 100, 200],  \n",
    "    'RF_Model__criterion': ['gini', 'entropy'],  \n",
    "    'RF_Model__max_depth': [None, 10, 20, 30],  \n",
    "    'RF_Model__min_samples_split': [2, 5, 10],  \n",
    "    'RF_Model__min_samples_leaf': [1, 2, 4], \n",
    "    'RF_Model__max_features': ['sqrt', 'log2', None],  \n",
    "    'RF_Model__bootstrap': [True,],  \n",
    "    'RF_Model__ccp_alpha': [0.0, 0.01, 0.1], \n",
    "    'RF_Model__max_samples': [None, 0.5, 0.75]  \n",
    "}\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=Base_RF_Model_Pipeline, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best score found: \", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b8810c-91dc-44e2-8e98-2be563c15054",
   "metadata": {},
   "source": [
    "### Grid Search Metrics For Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f9a5171-4938-4a32-96eb-e216c56045ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5569727891156462\n",
      "Recall: 0.45467674532940017\n",
      "Precision: 0.4513094190140845\n",
      "F1 Score: 0.45243897270723854\n"
     ]
    }
   ],
   "source": [
    "# Create Model Pipeline\n",
    "Base_RF_Model_Pipeline = Pipeline(steps=[\n",
    "    ('Preprocessor', Preprocessor),\n",
    "    ('Feature_Selection', Selection),\n",
    "    ('RF_Model', RandomForestClassifier(random_state=42,\n",
    "                                       \n",
    "                                       ccp_alpha=  0.0,\n",
    "                                       criterion ='entropy',\n",
    "                                       max_depth= 20,\n",
    "                                       max_features= 'sqrt',\n",
    "                                       min_samples_leaf= 2,\n",
    "                                       min_samples_split= 2,\n",
    "                                       n_estimators= 100,\n",
    "                                       bootstrap= False,\n",
    "                                       max_samples= None,\n",
    "))  \n",
    "])\n",
    "\n",
    "# Perform cross-validation\n",
    "RF_CV_accuracy = cross_val_score(Base_RF_Model_Pipeline, X, Y, cv=10, scoring='accuracy').mean()\n",
    "RF_CV_predictions = cross_val_predict(Base_RF_Model_Pipeline, X, Y, cv=10)\n",
    "\n",
    "# Calculate recall, precision, and F1 score for each fold\n",
    "RF_CV_recall = recall_score(Y, RF_CV_predictions, average=None).mean()\n",
    "RF_CV_precision = precision_score(Y, RF_CV_predictions, average=None).mean()\n",
    "RF_CV_f1_score = f1_score(Y, RF_CV_predictions, average=None).mean()\n",
    "\n",
    "# Display the metrics\n",
    "print(\"Accuracy:\", RF_CV_accuracy)\n",
    "print(\"Recall:\", RF_CV_recall)\n",
    "print(\"Precision:\", RF_CV_precision)\n",
    "print(\"F1 Score:\", RF_CV_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "41c1a77c-419c-42b9-8f7d-069926615950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ??RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24154e0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T07:23:54.138024Z",
     "start_time": "2024-04-09T07:23:54.120568Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Define the parameter grid, prefixing each parameter with the name of the pipeline step followed by two underscores\n",
    "# param_grid = {\n",
    "#     'GBC_Model__loss': ['deviance', 'exponential'],\n",
    "#     'GBC_Model__learning_rate': [0.01, 0.1, 0.5],\n",
    "#     'GBC_Model__n_estimators': [50, 100, 200],\n",
    "#     'GBC_Model__subsample': [0.5, 0.75, 1.0],\n",
    "#     'GBC_Model__criterion': ['friedman_mse', 'mse', 'mae'],\n",
    "#     'GBC_Model__min_samples_split': [2, 5, 10],\n",
    "#     'GBC_Model__min_samples_leaf': [1, 2, 4],\n",
    "#     'GBC_Model__max_depth': [3, 5, 10],\n",
    "#     'GBC_Model__min_impurity_decrease': [0.0, 0.1, 0.2],\n",
    "#     'GBC_Model__max_features': ['auto', 'sqrt', 'log2', None],\n",
    "#     'GBC_Model__warm_start': [True, False]\n",
    "# }\n",
    "\n",
    "# # Create GridSearchCV\n",
    "# grid_search = GridSearchCV(estimator=Base_GBC_Model_Pipeline, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# # Fit the grid search to the data\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # Get the best parameters\n",
    "# best_params = grid_search.best_params_\n",
    "\n",
    "# print(\"Best parameters found:\")\n",
    "# print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b803889a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T07:23:54.758126Z",
     "start_time": "2024-04-09T07:23:54.143728Z"
    }
   },
   "outputs": [],
   "source": [
    "# ??RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02008b56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T07:23:54.766765Z",
     "start_time": "2024-04-09T07:23:54.761061Z"
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# # Define the parameter grid to use for the grid search\n",
    "# param_grid = {\n",
    "#     'RF_Model__n_estimators': [10, 20,30,50,75, 100,150, 200],  # Number of trees in the forest\n",
    "#     'RF_Model__criterion': ['gini', 'entropy'],  # Function to measure the quality of a split\n",
    "#     'RF_Model__max_depth': [None,5, 10,15, 20],  # Maximum depth of the tree\n",
    "#     'RF_Model__min_samples_split': [2, 5, 10, 15,],  # Minimum number of samples required to split an internal node\n",
    "#     'RF_Model__min_samples_leaf': [1,3, 5],  # Minimum number of samples required to be at a leaf node\n",
    "#     'RF_Model__max_features': ['sqrt', 'log2', None],  # Number of features to consider when looking for the best split\n",
    "#     # Note: For max_features, None means that max_features=n_features\n",
    "#     'RF_Model__bootstrap': [True, False],  # Whether bootstrap samples are used when building trees\n",
    "#     'RF_Model__ccp_alpha': [0.0, 0.01, 0.1],  # Complexity parameter used for Minimal Cost-Complexity Pruning\n",
    "#     'RF_Model__max_samples': [None,0.25, 0.5, 0.75]  # If bootstrap is True, the number of samples to draw from X to train each base estimator\n",
    "# }\n",
    "\n",
    "# # Create the GridSearchCV object\n",
    "# grid_search = GridSearchCV(estimator=Base_RF_Model_Pipeline, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "\n",
    "# # Assuming X_train and y_train are already defined\n",
    "# # Fit the grid search to the data\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # Print the best parameters and the best score\n",
    "# print(\"Best parameters found: \", grid_search.best_params_)\n",
    "# print(\"Best score found: \", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f602b90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83217de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0ccfcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c364750",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebef77c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5adcc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f58be31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T07:23:54.792102Z",
     "start_time": "2024-04-09T07:23:54.770051Z"
    }
   },
   "outputs": [],
   "source": [
    "# #Create Pipeline to be used in Gradient Boosting Classfier Model\n",
    "# Base_GBC_Model_Pipeline = Pipeline(steps=[\n",
    "#     ('Preprocessor', Preprocessor),\n",
    "#     ('GBC_Model',GradientBoostingClassifier())])\n",
    "\n",
    "# # Perform cross-validation\n",
    "# GBC_CV_accuracy = cross_val_score(Base_GBC_Model_Pipeline, X, Y, cv=5, scoring='accuracy').mean()\n",
    "# GBC_CV_predictions = cross_val_predict(Base_GBC_Model_Pipeline, X, Y, cv=5)\n",
    "\n",
    "# # Calculate recall, precision, and F1 score for each fold\n",
    "# GBC_CV_recall = recall_score(Y, GBC_CV_predictions, average=None).mean()\n",
    "# GBC_CV_precision = precision_score(Y, GBC_CV_predictions, average=None).mean()\n",
    "# GBC_CV_f1_score = f1_score(Y, GBC_CV_predictions, average=None).mean()\n",
    "\n",
    "# # Display the metrics\n",
    "# print(\"Accuracy:\", GBC_CV_accuracy)\n",
    "# print(\"Recall:\", GBC_CV_recall)\n",
    "# print(\"Precision:\", GBC_CV_precision)\n",
    "# print(\"F1 Score:\", GBC_CV_f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70c163ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T07:23:56.743105Z",
     "start_time": "2024-04-09T07:23:54.795405Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5629939862542955\n",
      "Recall: 0.4670907079646017\n",
      "Precision: 0.4654887218045113\n",
      "F1 Score: 0.466013109566001\n"
     ]
    }
   ],
   "source": [
    "#Create Pipeline to be used in Gradient Boosting Classfier Model\n",
    "Base_GBC_Model_Pipeline = Pipeline(steps=[\n",
    "    ('Preprocessor', Preprocessor),\n",
    "    ('GBC_Model',GradientBoostingClassifier(\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "    subsample=.75,\n",
    "    criterion='friedman_mse',\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=4,\n",
    "    max_depth=5,\n",
    "    min_impurity_decrease=0.1,\n",
    "    random_state=42,\n",
    "    max_features='sqrt',\n",
    "    verbose=0,\n",
    "    max_leaf_nodes=None,\n",
    "    warm_start=False,\n",
    "    validation_fraction=0.1,\n",
    "   ))])\n",
    "\n",
    "# Perform cross-validation\n",
    "GBC_CV_accuracy = cross_val_score(Base_GBC_Model_Pipeline, X, Y, cv=5, scoring='accuracy').mean()\n",
    "GBC_CV_predictions = cross_val_predict(Base_GBC_Model_Pipeline, X, Y, cv=5)\n",
    "\n",
    "# Calculate recall, precision, and F1 score for each fold\n",
    "GBC_CV_recall = recall_score(Y, GBC_CV_predictions, average=None).mean()\n",
    "GBC_CV_precision = precision_score(Y, GBC_CV_predictions, average=None).mean()\n",
    "GBC_CV_f1_score = f1_score(Y, GBC_CV_predictions, average=None).mean()\n",
    "\n",
    "# Display the metrics\n",
    "print(\"Accuracy:\", GBC_CV_accuracy)\n",
    "print(\"Recall:\", GBC_CV_recall)\n",
    "print(\"Precision:\", GBC_CV_precision)\n",
    "print(\"F1 Score:\", GBC_CV_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a1d6570",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T07:23:57.812674Z",
     "start_time": "2024-04-09T07:23:56.759340Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold CV Results:\n",
      "Accuracy: 0.6833118556701031\n",
      "Recall: 0.8967954345917472\n",
      "Precision: 0.7205529209160536\n",
      "F1 Score: 0.7990249871289621\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "\n",
    "# Define StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define scoring metrics\n",
    "scoring = ['accuracy', 'recall', 'precision', 'f1']\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_results = cross_validate(Base_GBC_Model_Pipeline, X, Y, cv=skf, scoring=scoring)\n",
    "\n",
    "# Calculate the mean of each metric\n",
    "accuracy_mean = cv_results['test_accuracy'].mean()\n",
    "recall_mean = cv_results['test_recall'].mean()\n",
    "precision_mean = cv_results['test_precision'].mean()\n",
    "f1_mean = cv_results['test_f1'].mean()\n",
    "\n",
    "print(\"StratifiedKFold CV Results:\")\n",
    "print(f\"Accuracy: {accuracy_mean}\")\n",
    "print(f\"Recall: {recall_mean}\")\n",
    "print(f\"Precision: {precision_mean}\")\n",
    "print(f\"F1 Score: {f1_mean}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295ccef9-2f3e-4227-bcd7-c9b7fdb9eaa7",
   "metadata": {},
   "source": [
    "# Tuned Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3e2e7fe1-c0e9-454a-84b8-48f7e2664984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 0.75\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Loss Trades       0.67      0.15      0.25        13\n",
      "  Win Trades       0.76      0.97      0.85        35\n",
      "\n",
      "    accuracy                           0.75        48\n",
      "   macro avg       0.71      0.56      0.55        48\n",
      "weighted avg       0.73      0.75      0.69        48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create Pipeline to be used in Gradient Boosting Classfier Model\n",
    "Base_GBC_Model_Pipeline = Pipeline(steps=[\n",
    "    ('Preprocessor', Preprocessor),\n",
    "    ('GBC_Model',GradientBoostingClassifier(\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "    subsample=.75,\n",
    "    criterion='friedman_mse',\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=4,\n",
    "    max_depth=5,\n",
    "    min_impurity_decrease=0.1,\n",
    "    random_state=42,\n",
    "    max_features='sqrt',\n",
    "    verbose=0,\n",
    "    max_leaf_nodes=None,\n",
    "    warm_start=False,\n",
    "    validation_fraction=0.1,\n",
    "   ))])\n",
    "\n",
    "#Fit the training data \n",
    "Base_GBC_Model_Pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Perform cross-validation\n",
    "GBC_predictions = Base_GBC_Model_Pipeline.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, GBC_predictions)\n",
    "print(f\"\\nTest Accuracy: {accuracy}\\n\")\n",
    "\n",
    "# Generate  and Print a classification report\n",
    "report = classification_report(y_test, GBC_predictions, target_names=[\"Loss Trades\", \"Win Trades\"]) \n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04610254-1ccb-4a38-971e-ef9f07126dbd",
   "metadata": {},
   "source": [
    "## Summary and Key Takeaways\n",
    "\n",
    "### Performance Overview\n",
    "- **Test Accuracy**: 75%.\n",
    "\n",
    "### Insights from Classification Report\n",
    "- **'Win Trades' (Positive Class)**:\n",
    "  - Precision: ~76%\n",
    "  - Recall: ~97%\n",
    "  - F1-score: ~0.85\n",
    "- **'Loss Trades' (Negative Class)**:\n",
    "  - Precision: ~67%\n",
    "  - Recall: ~15%\n",
    "  - F1-score: ~0.25\n",
    "\n",
    "### Key Takeaways\n",
    "1. **Strong Performance on Majority Class**:\n",
    "   - The model is highly effective in predicting 'Win Trades', with high precision and recall. This indicates strong performance for the majority class.\n",
    "2. **Challenges with Minority Class**:\n",
    "   - Despite a reasonable precision, the recall for 'Loss Trades' is very low, suggesting that the model struggles to identify this class correctly. The low recall for 'Loss Trades' needs addressing to balance the model's performance across classes.\n",
    "3. **Potential for Model Tuning**:\n",
    "   - Improving the model's ability to detect 'Loss Trades' could involve tuning hyperparameters, exploring different model architectures, or employing techniques aimed at balancing class representation.\n",
    "4. **Metrics Indicating Room for Improvement**:\n",
    "   - While the overall accuracy is good, the macro averages for precision, recall, and F1-score suggest that the performance across classes is uneven, reinforcing the need for model refinement to ensure fairness and robustness.\n",
    "\n",
    "This summary pinpoints where the model excels and where improvements are necessary, especially in handling the minority class more effectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a5d8a3-5cb8-41dc-adab-60e9c33627bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed90129-5bda-4b8e-87f3-ddb47015dfce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47090d13-2f96-4d3a-8e6e-ae4ed969e7c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcad4bc-21b8-45ce-80c6-99ffafcebb10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b826792-34f8-4901-9060-987aad4cf79e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ddd181-9079-4fb4-8539-b8764552daee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f1b65f-cf35-40af-9ebf-d2499cd8d892",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584cc684-9d6b-472a-9dfd-4fadf41179b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24227caf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T07:23:58.869519Z",
     "start_time": "2024-04-09T07:23:57.816028Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# Define ShuffleSplit\n",
    "ss = ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_results = cross_validate(Base_GBC_Model_Pipeline, X, Y, cv=ss, scoring=scoring)\n",
    "\n",
    "# Calculate the mean of each metric\n",
    "accuracy_mean = cv_results['test_accuracy'].mean()\n",
    "recall_mean = cv_results['test_recall'].mean()\n",
    "precision_mean = cv_results['test_precision'].mean()\n",
    "f1_mean = cv_results['test_f1'].mean()\n",
    "\n",
    "print(\"ShuffleSplit CV Results:\")\n",
    "print(f\"Accuracy: {accuracy_mean}\")\n",
    "print(f\"Recall: {recall_mean}\")\n",
    "print(f\"Precision: {precision_mean}\")\n",
    "print(f\"F1 Score: {f1_mean}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3463dfdc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T07:23:58.889248Z",
     "start_time": "2024-04-09T07:23:58.883957Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8caf0a3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T07:23:58.927870Z",
     "start_time": "2024-04-09T07:23:58.893189Z"
    }
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# # Given values\n",
    "# values = [0.01, 0.1, 0.5]\n",
    "\n",
    "# # Using list comprehension with numpy.array to recreate the list\n",
    "# list_from_numpy = [np.array(values)[i] for i in range(len(values))]\n",
    "\n",
    "# print(list_from_numpy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cc32a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T23:54:47.114040Z",
     "start_time": "2024-04-08T23:54:47.088402Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0b20031",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T07:23:58.961274Z",
     "start_time": "2024-04-09T07:23:58.938982Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Define the parameter grid, prefixing each parameter with the name of the pipeline step followed by two underscores\n",
    "# param_grid = {\n",
    "#     'GBC_Model__loss': ['deviance', 'exponential'],\n",
    "#     'GBC_Model__learning_rate': [0.01, 0.1, 0.5],\n",
    "#     'GBC_Model__n_estimators': [50, 100, 200],\n",
    "#     'GBC_Model__subsample': [0.5, 0.75, 1.0],\n",
    "#     'GBC_Model__criterion': ['friedman_mse', 'mse', 'mae'],\n",
    "#     'GBC_Model__min_samples_split': [2, 5, 10],\n",
    "#     'GBC_Model__min_samples_leaf': [1, 2, 4],\n",
    "#     'GBC_Model__max_depth': [3, 5, 10],\n",
    "#     'GBC_Model__min_impurity_decrease': [0.0, 0.1, 0.2],\n",
    "#     'GBC_Model__max_features': ['auto', 'sqrt', 'log2', None],\n",
    "#     'GBC_Model__warm_start': [True, False]\n",
    "# }\n",
    "\n",
    "# # Create GridSearchCV\n",
    "# grid_search = GridSearchCV(estimator=Base_GBC_Model_Pipeline, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# # Fit the grid search to the data\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # Get the best parameters\n",
    "# best_params = grid_search.best_params_\n",
    "\n",
    "# print(\"Best parameters found:\")\n",
    "# print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7dc7c9ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T07:23:58.993280Z",
     "start_time": "2024-04-09T07:23:58.966731Z"
    }
   },
   "outputs": [],
   "source": [
    "# grid = GridSearchCV(Base_GBC_Model_Pipeline, params, cv=5, scoring='accuracy')\n",
    "# grid.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe24d099",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T07:23:59.012861Z",
     "start_time": "2024-04-09T07:23:59.006952Z"
    }
   },
   "outputs": [],
   "source": [
    "# ??GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2133339",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T07:23:59.037063Z",
     "start_time": "2024-04-09T07:23:59.022266Z"
    }
   },
   "outputs": [],
   "source": [
    "# Best parameters found:\n",
    "# {'GBC_Model__criterion': 'friedman_mse',\n",
    "#  'GBC_Model__learning_rate': 0.1, \n",
    "#  'GBC_Model__loss': 'exponential',\n",
    "#  'GBC_Model__max_depth': 5,\n",
    "#  'GBC_Model__max_features': 'sqrt', \n",
    "#  'GBC_Model__min_impurity_decrease': 0.1,\n",
    "#  'GBC_Model__min_samples_leaf': 4, \n",
    "#  'GBC_Model__min_samples_split': 10,\n",
    "#  'GBC_Model__n_estimators': 100,\n",
    "#  'GBC_Model__subsample': 0.75,\n",
    "#  'GBC_Model__warm_start': False}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0b0a1b",
   "metadata": {},
   "source": [
    "### Base Model Summary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14efeb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T07:23:59.569618Z",
     "start_time": "2024-04-09T07:23:59.569563Z"
    }
   },
   "outputs": [],
   "source": [
    "#Create a dataframe to score metric scores\n",
    "Classifier_Scores = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f614aaf0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T07:23:59.579151Z",
     "start_time": "2024-04-09T07:23:59.579108Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame to store these values\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Logistic Regression': [LR_Accuracy, LR_f_score, LR_recall_, LR_precision],\n",
    "    'Descision Tree' : [DT_Accuracy, DT_f_score, DT_recall_, DT_precision],\n",
    "    'Support Vector Machine' : [SVC_Accuracy, SVC_f_score, SVC_recall_, SVC_precision],\n",
    "    'Random Forest' : [RF_Accuracy, RF_f_score, RF_recall_, RF_precision],\n",
    "    'Gradient Boosting' : [GBC_Accuracy, GBC_f_score, GBC_recall_, GBC_precision],\n",
    "    'ADA Boost ' : [ADAC_Accuracy, ADAC_f_score, ADAC_recall_, ADAC_precision],\n",
    "}, index=['Accuracy','F1 Score', 'Recall', 'Precision'])\n",
    "\n",
    "# Transpose the DataFrame \n",
    "metrics_df = metrics_df.transpose()\n",
    "\n",
    "#rename the index \n",
    "metrics_df.index.name='Model Name'\n",
    "\n",
    "metrics_df.reset_index(inplace=True)\n",
    "\n",
    "# # Display the DataFrame\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd9c425",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T07:23:59.588070Z",
     "start_time": "2024-04-09T07:23:59.588026Z"
    }
   },
   "outputs": [],
   "source": [
    "#Sort the df based on each metric \n",
    "accuracy_sorted_df = metrics_df.sort_values('Accuracy',ascending=False)\n",
    "f1_sorted_df = metrics_df.sort_values('F1 Score',ascending=False)\n",
    "recall_sorted_df = metrics_df.sort_values('Recall',ascending=False)\n",
    "precision_sorted_df = metrics_df.sort_values('Precision',ascending=False)\n",
    "\n",
    "#Create Figure \n",
    "fig, axs= plt.subplots(1,4, figsize=(24,10))\n",
    "\n",
    "fig.suptitle(\"Base Model Performance\",fontsize=16)\n",
    "\n",
    "#Plot Accuracy in AXS[0,0]\n",
    "bar_accuracy = axs[0].bar(accuracy_sorted_df['Model Name'], accuracy_sorted_df['Accuracy'])\n",
    "axs[0].set_title('Accuracy By Classifiers')\n",
    "axs[0].set_ylabel('Percentage %')\n",
    "axs[0].set_xticklabels(accuracy_sorted_df['Model Name'], rotation=45)\n",
    "for bar in bar_accuracy:\n",
    "    height = bar.get_height()\n",
    "    axs[0].text(bar.get_x() + bar.get_width() / 2, height, f'{height:.2f}%', ha='center', va='bottom')\n",
    "\n",
    "#Plot Precision in AXS[1[]\n",
    "bar_precision = axs[1].bar(precision_sorted_df['Model Name'], precision_sorted_df['Precision'])\n",
    "axs[1].set_title('Precision By Classifiers')\n",
    "axs[1].set_ylabel('Percentage %')\n",
    "axs[1].set_xticklabels(precision_sorted_df['Model Name'], rotation=45)\n",
    "for bar in bar_precision:\n",
    "    height = bar.get_height()\n",
    "    axs[1].text(bar.get_x() + bar.get_width() / 2, height, f'{height:.2f}%', ha='center', va='bottom')\n",
    "\n",
    "#Plot Recall in AXS[2]\n",
    "bar_recall = axs[2].bar(recall_sorted_df['Model Name'], recall_sorted_df['Recall'])\n",
    "axs[2].set_title('Recall By Classifiers')\n",
    "axs[2].set_ylabel('Percentage %')\n",
    "axs[2].set_xticklabels(recall_sorted_df['Model Name'], rotation=45)\n",
    "for bar in bar_recall:\n",
    "    height = bar.get_height()\n",
    "    axs[2].text(bar.get_x() + bar.get_width() / 2, height, f'{height:.2f}%', ha='center', va='bottom')\n",
    "    \n",
    "#Plot F1 Score in AXS[3]\n",
    "bar_fscore = axs[3].bar(f1_sorted_df['Model Name'], f1_sorted_df['F1 Score'])\n",
    "axs[3].set_title('F1 Score By Classifiers')\n",
    "axs[3].set_ylabel('Percentage %')\n",
    "axs[3].set_xticklabels(f1_sorted_df['Model Name'], rotation=45)\n",
    "for bar in bar_fscore:\n",
    "    height = bar.get_height()\n",
    "    axs[3].text(bar.get_x() + bar.get_width() / 2, height, f'{height:.2f}%', ha='center', va='bottom')\n",
    "    \n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f373a1",
   "metadata": {},
   "source": [
    "### There might be an issue between the Recall and Precision value of Logistic Regression - do not delete this until investigate further "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ecb6ee",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cc5fd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T07:23:59.592428Z",
     "start_time": "2024-04-09T07:23:59.592390Z"
    }
   },
   "outputs": [],
   "source": [
    "#Retrived the Feature Selection Step \n",
    "feature_selection = Base_RF_Model_Pipeline.named_steps['Feature_Selection']\n",
    "\n",
    "#Retrieve the trained model \n",
    "trained_RF_Model = Base_RF_Model_Pipeline.named_steps['RF_Model']\n",
    "\n",
    "feature_importances = trained_RF_Model.feature_importances_\n",
    "\n",
    "# Get the indices of selected features\n",
    "selected_feature_indices = feature_selection.get_support(indices=True)\n",
    "\n",
    "# Extract feature names\n",
    "all_feature_names = Preprocessor.get_feature_names_out()\n",
    "selected_feature_names = [all_feature_names[i] for i in selected_feature_indices]\n",
    "\n",
    "# Combine feature names with their importances\n",
    "features_and_importances = zip(selected_feature_names, feature_importances)\n",
    "\n",
    "# Sort features by importance\n",
    "sorted_features_and_importances = sorted(features_and_importances, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "\n",
    "# Create a DataFrame from the features and importances\n",
    "feature_importance_df = pd.DataFrame(sorted_features_and_importances, columns=['Feature', 'Importance'])\n",
    "\n",
    "# Display the DataFrame\n",
    "feature_importance_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53fe12b",
   "metadata": {},
   "source": [
    "### Reference: Concepts To Understand \n",
    "\n",
    "#### Accuracy: \n",
    "                - Measures the overall correctness of the classifier. It's calculated by dividing the number of correctly classifier samples by the total number of samples. \n",
    "                - Accuracy tells us how often the classifier correctly predicted whether a trade is a successful or not compared to the total number of trades.\n",
    "                - An Accuracy of .76 means that classifier correctly predicted the trade status for approximately 76% of the time. \n",
    "                \n",
    "#### Recall:\n",
    "             - Also known as sensitivity or true positive, measures  the ability of the classifier to correctly identify all positive instances. \n",
    "             - In the context of a trade status classifier, recall tells us how often the classifier correctly identified out of all successful trades.\n",
    "             - A recall of approximately .795 means that the classifier correctly identified 79.5% of the successful trades. \n",
    "#### Precision \n",
    "              - Measures the ability of the classifier to correctly identify only relevant instances among all instances it has classified as positive. \n",
    "              - In the context of a trade status classifier, precision measures the proportion of correctly predicted successful trades out of all successful trades.\n",
    "              - A precision of approximately .933 means that about 93.3% of the trades predicted as successful by the classifier were actually successful. \n",
    "#### F1 Score\n",
    "                - Is a metric that combines precision and recall into a single value - it is the harmonic mean between precision and recall. \n",
    "                - Precision measures the proportion of correctly predicted positive cases among all predicted cases.\n",
    "                - While Recall, measures the proportion of correctly predicted positive cases among all actual positive cases.\n",
    "                - F1 Score provides a balance between precision and recall, it is especially useful when there is an uneven class distribution.\n",
    "                - In the context of a trade status classifier, an F1 Score of .859 indicate a good balance between precision and recall predicting whether trades were successful or not. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
